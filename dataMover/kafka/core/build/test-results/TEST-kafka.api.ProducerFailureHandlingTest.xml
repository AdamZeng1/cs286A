<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="kafka.api.ProducerFailureHandlingTest" tests="11" skipped="0" failures="0" errors="0" timestamp="2015-03-27T21:38:49" hostname="airbears2-10-142-35-31.AirBears2.1918.Berkeley.EDU" time="66.03">
  <properties/>
  <testcase name="testTooLargeRecordWithAckOne" classname="kafka.api.ProducerFailureHandlingTest" time="2.083"/>
  <testcase name="testNonExistentTopic" classname="kafka.api.ProducerFailureHandlingTest" time="4.743"/>
  <testcase name="testWrongBrokerList" classname="kafka.api.ProducerFailureHandlingTest" time="4.919"/>
  <testcase name="testInvalidPartition" classname="kafka.api.ProducerFailureHandlingTest" time="2.281"/>
  <testcase name="testSendAfterClosed" classname="kafka.api.ProducerFailureHandlingTest" time="2.294"/>
  <testcase name="testBrokerFailure" classname="kafka.api.ProducerFailureHandlingTest" time="13.208"/>
  <testcase name="testNotEnoughReplicas" classname="kafka.api.ProducerFailureHandlingTest" time="2.071"/>
  <testcase name="testTooLargeRecordWithAckZero" classname="kafka.api.ProducerFailureHandlingTest" time="2.281"/>
  <testcase name="testCannotSendToInternalTopic" classname="kafka.api.ProducerFailureHandlingTest" time="2.09"/>
  <testcase name="testNoResponse" classname="kafka.api.ProducerFailureHandlingTest" time="8.211"/>
  <testcase name="testNotEnoughReplicasAfterBrokerShutdown" classname="kafka.api.ProducerFailureHandlingTest" time="21.848"/>
  <system-out><![CDATA[[2015-03-27 14:38:51,976] WARN Exception causing close of session 0x0 due to java.io.IOException: ZooKeeperServer not running (org.apache.zookeeper.server.NIOServerCnxn:362)
[2015-03-27 14:39:19,786] ERROR [Replica Manager on Broker 1]: Error processing append operation on partition [minisrtest,0] (kafka.server.ReplicaManager:103)
kafka.common.NotEnoughReplicasException: Number of insync replicas for partition [minisrtest,0] is [3], below required minimum [2]
	at kafka.cluster.Partition$$anonfun$appendMessagesToLeader$1.apply(Partition.scala:411)
	at kafka.cluster.Partition$$anonfun$appendMessagesToLeader$1.apply(Partition.scala:401)
	at kafka.utils.Utils$.inLock(Utils.scala:566)
	at kafka.utils.Utils$.inReadLock(Utils.scala:572)
	at kafka.cluster.Partition.appendMessagesToLeader(Partition.scala:401)
	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$2.apply(ReplicaManager.scala:342)
	at kafka.server.ReplicaManager$$anonfun$appendToLocalLog$2.apply(ReplicaManager.scala:327)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:98)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:226)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:39)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:98)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at kafka.server.ReplicaManager.appendToLocalLog(ReplicaManager.scala:327)
	at kafka.server.ReplicaManager.appendMessages(ReplicaManager.scala:263)
	at kafka.server.KafkaApis.handleProducerRequest(KafkaApis.scala:235)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:60)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:59)
	at java.lang.Thread.run(Thread.java:744)
[2015-03-27 14:39:20,663] WARN caught end of stream exception (org.apache.zookeeper.server.NIOServerCnxn:357)
EndOfStreamException: Unable to read additional data from client sessionid 0x14c5d2cccfc0001, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:744)
]]></system-out>
  <system-err><![CDATA[]]></system-err>
</testsuite>
